<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Homepage of Sourish Dhekane</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="fade-in">

				<!-- Intro -->
					<div id="intro">
						<h1>Sourish Gunesh Dhekane<br />
						
						 <p>Welcome to my homepage!</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Home</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Academic</a></li>
							<li><a href="generic.html">Personal</a></li>
							<li><a href="elements.html">Fun Stuff</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/sourish-dhekane-116ab1142/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="https://github.com/sourishdhekane" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.facebook.com/sourish.dhekane/" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="https://twitter.com/DhekaneSourish" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Featured Post -->
							<article class="post featured">
								<header class="major">
									<h2>Educational Background</h2>
									<p>I have completed my undergraduate studies (B.Tech. in Computer Science and Engineering) from Indian Institute of Information Technology Guwahati (<a href="http://www.iiitg.ac.in/"><span class="label">IIITG</span></a>) with a CGPA of 9.32/10 and Department Rank 1. My academic transcript for B.Tech. can be found <a href="https://drive.google.com/file/d/14xDzNw8FIbMimWcZo-kuc_HsJbz6mmKN/view?usp=sharing"><span class="label">here</span></a>.
									Prior to that, I completed my High School and Middle School Education from S. P. College and Jnana Prabodhini Prashala, Pune.<br />
									</p>
								</header>
								<a href="#" class="image main"><img src="images/pic01.jpg" alt="" /></a>
								<ul class="actions special">
									<li><a href="#" class="button large">Home</a></li>
								</ul>
							</article>

							<article class="post featured">
								<header class="major">
									<h2>Research Interests</h2>
									<p>During my undergraduate years, I have developed a keen research interest in the domains of Machine Learning, Computer Vision, and Deep Learning. In particular, I have worked on research projects in the areas of Semi-Supervised Learning, Remote Sensing, Image Segmentation, Theoretical Analysis of Machine Learning Performance Measures, and Activity/Subject Recognition for Smart-Home Settings. I have also spent time as a research intern at <a href="https://www.isical.ac.in/"><span class="label">ISI Kolkata</span></a> and <a href="http://wcm-3.unipv.it/site/en/home.html"><span class="label">University of Pavia</span></a> under the guidance of Dr. Swagatam Das and Prof. Paolo Gamba. The link to my Google Scholar profile can be found <a href="https://scholar.google.com/citations?user=YPqneNoAAAAJ&hl=en"><span class="label">here</span></a>. A brief description of my research projects is given below.  
									</p>
								</header>
								<a href="#" class="image main 1"><img src="images/me_comsnet.jpg" alt="" /></a>
								<ul class="actions special">
									<li><a href="#" class="button large">Home</a></li>
								</ul>
							</article>


						<!-- Posts -->
							<section class="posts">
								<article>
									<header>
										<span class="date">February 2020 -- Present</span>
										<h2><a href="#">Semi-supervised Subject Recognition in Low-Modal Sensor Data
										</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic02.png" alt="" /></a>
									<p>Subject Recognition (SR) refers to the task of identifying persons performing activities in a smart environment using the data captured by the sensors installed in it. The existing literature mainly concentrates on supervised SR using the sensor data captured through multiple modalities. However, majority of the real-life sensor datasets are not annotated with the subjects performing the activities, which creates a scarcity of labeled data samples for this task.   Issues of privacy and high manual annotation costs further complicate the problem of less labeled data. In addition to this problem, most of the datasets are of low modalities. Hence, the challenge lies in developing semi-supervised frameworks that are suitable for low-modal sensor data with sparse or no labels. Towards this, we initially perform benchmark experiments to analyze the factors of modality and amount of labeled data in the context of SR. Then, we propose  semi-supervised frameworks for  SR on the data collected by low-modal ubiquitous and visual sensors. In particular, we propose a clustering-based pseudo label generation algorithm to facilitate the training process in a semi-supervised domain for ubiquitous data. On the other hand, we propose Transfer Learning and Data Augmentation (TLDA) framework to perform SR on visual data in semi-supervised domain. To validate our proposed frameworks, we perform experiments on three real-world datasets, namely Smartphone, OPPORTUNITY,and UTD-MHAD dataset to achieve an accuracy of around 77%, 98%, and 91% respectively. Finally, we also provide an analysis on the aspect of merging modalities to propose a new research dimension for SR.</p>
									<ul class="actions special">
										<li><a href="#" class="button">Paper Link</a></li>
									</ul>
								</article>
								<article>
									<header>
										<span class="date">October 2019 -- Present</span>
										<h2><a href="#">Enhanced Annotation Framework for Activity Recognition Through ChangePoint Detection</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic03.png" alt="" /></a>
									<p>
									The task of Activity Recognition (AR) on ubiquitous sensor data has become an active research domain due to the development and widespread use of low-cost commodity sensor devices. 
                                    Traditionally, this task is performed on annotated datasets where manually identified change points denoting the start and the end of the data points are present.
									However, majority of the real-world smart home applications generate un-annotated data streams, where such change points are not known in prior. 
									In this paper, we address this problem by proposing a real-time annotation framework for Activity Recognition based on Change Point Detection (CPD).
									First, we investigate the components of feature extraction, data augmentation, noise handling, and classification to propose the state-of-the-art activity recognition framework. 
									We then propose S-CPD, a novel transfer learning based CPD algorithm, which uses similarity of probability distributions in order to generate a change point index (CPI) corresponding to each of the sensor reading in the data stream. 
									Based on this calculated CPI, we segment the data stream and allows us to perform enhanced annotations.  
									To test the efficiency of this proposed annotation framework, we perform extensive experimentation on real-world smart home datasets. Our proposed solutions achieve state-of-the-art results for the tasks of AR and annotation on all the selected datasets, which outperform the existing best methods by around 1.6% and 14% respectively. 
									In addition, our S-CPD algorithm provides comparable performance with that of the state-of-the-art CPD algorithm. </p>
									<ul class="actions special">
										<li><a href="#" class="button">Paper Link</a></li>
									</ul>
								</article>
								<article>
									<header>
										<span class="date">September 2019</span>
										<h2><a href="#">Semi-supervised Subject Recognition through Pseudo Label Generation in Ubiquitous Sensor Data</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic04.png" alt="" /></a>
									<p>The task of gait-based subject recognition (SR) in ubiquitous sensor environments has become popular due to its wide range of applications in biometric authentication and smart home products. In recent times, a significant amount of work has been done in SR using supervised learning algorithms on datasets having high modality. However, the process of annotation for SR is difficult due to the challenges like privacy and high manual cost, which results in a scarcity of labeled data samples. Also, for the datasets having less modality, the task of SR in a semi-supervised domain is sparsely explored and challenging. In this work, we analyze the effect of these two factors (sparse labels and low modality) which are critical for SR in ubiquitous data. We select two datasets of ubiquitous data that are relatively unexplored in the context of SR. The datasets, namely OPPORTUNITY and Smartphone used to perform SR using conventional supervised learning algorithms to benchmark the results. Then we perform extensive experimentation to analyze the effect of the aforementioned factors over the task of SR by studying the variations in classification accuracies. Next, we propose our semi-supervised framework for SR based on the concept of pseudo labels to counter the adverse effects of low modality and lack of labels. Experimental results show that our approach offers up to 77% and 98% accuracy on the Smartphone and OPPORTUNITY dataset respectively.</p>
									<ul class="actions special">
										<li><a href="https://ieeexplore.ieee.org/abstract/document/9027441/" class="button">Paper Link</a></li>
									</ul>
								</article>
								<article>
									<header>
										<span class="date">May 2018</span>
										<h2><a href="#">Appropriateness of Performance Indices for Imbalanced Data Classification: An Analysis</h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic05.png" alt="" /></a>
									<p>Indices quantifying the performance of classifiers under class-imbalance, often suffer from distortions depending on the constitution of the test set or the class-specific classification accuracy, creating difficulties in assessing the merit of the classifier. We identify two fundamental conditions that a performance index must satisfy to be respectively resilient to altering number of testing instances from each class and the number of classes in the test set. In light of these conditions, under the effect of class imbalance, we theoretically analyze four indices commonly used for evaluating binary classifiers and five popular indices for multi-class classifiers. For indices violating any of the conditions, we also suggest remedial modification and normalization. We further investigate the capability of the indices to retain information about the classification performance over all the classes, even when the classifier exhibits extreme performance on some classes. Simulation studies are performed on high dimensional deep representations of subset of the ImageNet dataset using four state-of-the-art classifiers tailored for handling class imbalance. Finally, based on our theoretical findings and empirical evidence, we recommend the appropriate indices that should be used to evaluate the performance of classifiers in presence of class-imbalance.</p>
									<ul class="actions special">
										<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320320300042" class="button">Paper Link</a></li>
									</ul>
								</article>
								<article>
									<header>
										<span class="date">April 2019</span>
										<h2><a href="#">Hyperspectral Image Classification using Semi- supervised Deep Learning Strategies</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic06.png" alt="" /></a>
									<p>Recent development in deep learning (DL) methodologies have shown promising results on various computer vision tasks including classification of hyperspectral data. However, these methodologies are expected to suffer in the presence of lack of training data, due to complex network architecture and a large number of parameters. In this paper, various K-means based clustering techniques are explored to generate pseudo labels to facilitate the training of deep networks. To tackle the curse of dimensionality, an auto-encoder (AE) based dimensionality reduction method is employed. Finally, the classification is done using Convolutional Long Short Term Memory Cells (ConvLSTM) which outperforms the rest of the deep neural networks used. In addition, an analysis of the effect of the proposed dimensionality reduction method on clas- sification accuracy is presented. The efficacy of the proposed approach is demonstrated on two real-world hyperspectral image data sets namely the “University of Pavia” (UP) and “Salinas”.</p>
									<ul class="actions special">
										<li><a href="http://www.igs.org.in:8080/portal/igc-proceedings/igc-2019-surat-proceedings/TH13/TH13-32.pdf" class="button">Paper Link</a></li>
									</ul>
								</article>
								<article>
									<header>
										<span class="date">May 2018</span>
										<h2><a href="#">Hyperspectral Image Classification Using Semi-supervised Random Forest</a></h2>
									</header>
									<a href="#" class="image fit"><img src="images/pic07.png" alt="" /></a>
									<p>In this paper, a hyperspectral image classification technique is proposed using semi-supervised random forest (SSRF). Robust node splitting in the random forest requires enormous training data, which is scarce in remote sensing applications. In order to overcome this drawback, we propose utilizing unlabeled data in conjunction with labeled data to assist the splitting process. Moreover, in order to tackle the curse of dimensionality associated with a hyperspectral image, we explore nonnegative matrix factorization (NMF) to remove redundant information. Experimental results confirm the efficacy of the proposed method.</p>
									<ul class="actions special">
										<li><a href="https://link.springer.com/chapter/10.1007/978-3-030-00665-5_102" class="button">Paper Link</a></li>
									</ul>
								</article>
							</section>

						<!-- Footer -->
							


					</div>

				<!-- Footer -->
					

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Sourish Dhekane, 2020</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
